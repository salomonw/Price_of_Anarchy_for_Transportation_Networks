{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "unshift!(PyVector(pyimport(\"sys\")[\"path\"]), \"\");\n",
    "@pyimport matplotlib.pyplot as plt\n",
    "@pyimport numpy as np\n",
    "@pyimport json\n",
    "@pyimport os\n",
    "@pyimport pickle\n",
    "@pyimport pandas as pd\n",
    "@pyimport collections\n",
    "\n",
    "@pyimport parameters_julia\n",
    "@pyimport utils_julia\n",
    "\n",
    "out_dir = parameters_julia.out_dir;\n",
    "files_ID = parameters_julia.files_ID;\n",
    "month_w = parameters_julia.month_w;\n",
    "year = parameters_julia.year;\n",
    "instances_1 = parameters_julia.instances_ID;\n",
    "deg_grid = parameters_julia.deg_grid;\n",
    "c_grid = parameters_julia.c_grid;\n",
    "lamb_grid = parameters_julia.lamb_grid;\n",
    "week_day_Apr_list = parameters_julia.week_day_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport GLS_julia\n",
    "@pyimport Compute_Jacobian\n",
    "\n",
    "numNodes = Compute_Jacobian.numNodes;\n",
    "numLinks = Compute_Jacobian.numLinks;\n",
    "numODpairs = Compute_Jacobian.numODpairs;\n",
    "numZones = Compute_Jacobian.numZones\n",
    "od_pairs = Compute_Jacobian.od_pairs;\n",
    "link_list_js = Compute_Jacobian.link_list_js;\n",
    "link_length_list = Compute_Jacobian.link_length_list;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_demand_file (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_demand_file(file_path, n_nodes);\n",
    "    file = open(file_path)\n",
    "    demands = Dict()\n",
    "    n = n_nodes  # number of nodes\n",
    "    for i = 1:n\n",
    "        demands[(i,i)] = 0.0\n",
    "    end\n",
    "    for line in eachline(file)\n",
    "        OD_demand = split(line, \",\")\n",
    "        key, value = (parse(Int, OD_demand[1]), parse(Int, OD_demand[2])), parse(Float64, split(OD_demand[3], \"\\n\")[1])\n",
    "        demands[key] = value\n",
    "    end\n",
    "    close(file)\n",
    "    return demands\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sioux Falls network data\n",
    "# http://www.bgu.ac.il/~bargera/tntp/\n",
    "\n",
    "#Link travel time = free flow time * ( 1 + B * (flow/capacity)^Power ).\n",
    "#Link generalized cost = Link travel time + toll_factor * toll + distance_factor * distance\n",
    "\n",
    "# Traffic Assignment Data structure\n",
    "type TA_Data\n",
    "    network_name::String\n",
    "\n",
    "    number_of_zones::Int64\n",
    "    number_of_nodes::Int64\n",
    "    first_thru_node::Int64\n",
    "    number_of_links::Int64\n",
    "\n",
    "    start_node::Array\n",
    "    end_node::Array\n",
    "    capacity::Array\n",
    "    link_length::Array\n",
    "    free_flow_time::Array\n",
    "    B::Array\n",
    "    power::Array\n",
    "    speed_limit::Array\n",
    "    toll::Array\n",
    "    link_type::Array\n",
    "\n",
    "    total_od_flow::Float64\n",
    "\n",
    "    travel_demand::Array\n",
    "    od_pairs::Array\n",
    "\n",
    "    toll_factor::Float64\n",
    "    distance_factor::Float64\n",
    "\n",
    "    best_objective::Float64\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function load_ta_network_(out_dir, files_ID, month_w, day,  instan)\n",
    "    toll_factor = 0\n",
    "    distance_factor = 0\n",
    "    network_data_file = files_ID * \"_net_\" * month_w * \"_\" * string(day) * '_' * instan * \".txt\"\n",
    "    trip_table_file = files_ID * \"_trips_\" * month_w * \"_\" * string(day) * '_' * instan * \".txt\"\n",
    "    best_objective = 0\n",
    "\n",
    "    network_name = files_ID\n",
    "\n",
    "    network_data_file =  out_dir  * \"data_traffic_assignment_uni-class/\" * network_data_file\n",
    "    trip_table_file =   out_dir  * \"data_traffic_assignment_uni-class/\" * trip_table_file\n",
    "\n",
    "    number_of_zones = 0\n",
    "    number_of_links = 0\n",
    "    number_of_nodes = 0\n",
    "    first_thru_node = 0\n",
    "    \n",
    "    n = 0\n",
    "    A = 0\n",
    "    n = open(network_data_file, \"r\")\n",
    "    A = readlines(n)\n",
    "    for line in A\n",
    "        #print( line)\n",
    "        if contains(line, \"<NUMBER OF ZONES>\")\n",
    "            number_of_zones = parse( Int, line[ search(line, '>')+1 : end] )\n",
    "        elseif contains(line, \"<NUMBER OF NODES>\")\n",
    "            number_of_nodes = parse( Int, line[ search(line, '>')+1 : end] )\n",
    "        elseif contains(line, \"<FIRST THRU NODE>\")\n",
    "            first_thru_node = parse( Int, line[ search(line, '>')+1 : end] )\n",
    "        elseif contains(line, \"<NUMBER OF LINKS>\")\n",
    "            number_of_links = parse( Int, line[ search(line, '>')+1 : end] )\n",
    "        elseif contains(line, \"<END OF METADATA>\")\n",
    "       # println(line)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @assert number_of_links > 0\n",
    "    start_node = Array{Int}(number_of_links)\n",
    "    end_node = Array{Int}(number_of_links)\n",
    "    capacity = zeros(number_of_links)\n",
    "    link_length = zeros(number_of_links)\n",
    "    free_flow_time = zeros(number_of_links)\n",
    "    B = zeros(number_of_links)\n",
    "    power = zeros(number_of_links)\n",
    "    speed_limit = zeros(number_of_links)\n",
    "    toll = zeros(number_of_links)\n",
    "    link_type = Array{Int}(number_of_links)\n",
    "\n",
    "    idx = 1\n",
    "\n",
    "    apa = 0\n",
    "    for line in A\n",
    "        if contains(line, \"~\")\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if contains(line, \";\")\n",
    "            line = strip(line, '\\n')\n",
    "            line = strip(line, ';')\n",
    "            numbers = split(line)\n",
    "            start_node[idx] = parse(Int, numbers[1])\n",
    "            end_node[idx] = parse(Int, numbers[2])\n",
    "            \n",
    "            capacity[idx] = parse(Float64, numbers[3])\n",
    "            link_length[idx] = parse(Float64, numbers[4])\n",
    "            \n",
    "            free_flow_time[idx] = parse(Float64, numbers[5])\n",
    "            B[idx] = parse(Float64, numbers[6])\n",
    "            power[idx] = parse(Float64, numbers[7])\n",
    "            speed_limit[idx] = parse(Float64, numbers[8])\n",
    "            toll[idx] = parse(Float64, numbers[9])\n",
    "            link_type[idx] = parse(Float64, numbers[10])\n",
    "            \n",
    "            idx = idx + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ##################################################\n",
    "    # Trip Table\n",
    "    ##################################################\n",
    "\n",
    "    number_of_zones_trip = 0\n",
    "    total_od_flow = 0\n",
    "    \n",
    "    f = open(trip_table_file, \"r\")\n",
    "    fe = readlines(f)\n",
    "    \n",
    "    for line in fe\n",
    "        #println(line)\n",
    "        if contains(line, \"<NUMBER OF ZONES>\")\n",
    "            number_of_zones_trip = parse( Int, line[ search(line, '>')+1 : end ] )\n",
    "        elseif contains(line, \"<TOTAL OD FLOW>\")\n",
    "            total_od_flow = parse( Float64, line[ search(line, '>')+1 : end ] )\n",
    "        elseif contains(line, \"<END OF METADATA>\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @assert number_of_zones_trip == number_of_zones # Check if number_of_zone is same in both txt files\n",
    "\n",
    "    travel_demand = zeros(number_of_zones, number_of_zones)\n",
    "    od_pairs = []\n",
    "    origin = 0\n",
    "    for line in fe\n",
    "        if contains(line, \"Origin\")\n",
    "            origin = parse( Int, split(line)[2] )\n",
    "        elseif contains(line, \";\")\n",
    "            pairs = split(line, \";\")\n",
    "            for i=1:size(pairs)[1]\n",
    "                if contains(pairs[i], \":\")\n",
    "                    pair = split(pairs[i], \":\")\n",
    "                    destination = parse( Int, strip(pair[1]) )\n",
    "                    od_flow = parse( Float64, strip(pair[2]) )\n",
    "                    travel_demand[origin, destination] = od_flow\n",
    "                    push!(od_pairs, (origin, destination))\n",
    "                   # println(\"origin=$origin, destination=$destination, flow=$od_flow\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Preparing data to return\n",
    "    ta_data = TA_Data(\n",
    "        network_name,\n",
    "        number_of_zones,\n",
    "        number_of_nodes,\n",
    "        first_thru_node,\n",
    "        number_of_links,\n",
    "        start_node,\n",
    "        end_node,\n",
    "        capacity,\n",
    "        link_length,\n",
    "        free_flow_time,\n",
    "        B,\n",
    "        power,\n",
    "        speed_limit,\n",
    "        toll,\n",
    "        link_type,\n",
    "        total_od_flow,\n",
    "        travel_demand,\n",
    "        od_pairs,\n",
    "        toll_factor,\n",
    "        distance_factor,\n",
    "        best_objective)\n",
    "\n",
    "    return ta_data\n",
    "\n",
    "end # end of load_network  \n",
    "\n",
    "\n",
    "type Arc\n",
    "    initNode::Int \n",
    "    termNode::Int \n",
    "    capacity::Float64\n",
    "    freeflowtime::Float64\n",
    "    flow::Float64\n",
    "end\n",
    "\n",
    "Arc(initNode::Int, termNode::Int, capacity::Float64, freeflowtime::Float64) = \n",
    "    Arc(initNode, termNode, capacity, freeflowtime, 0.);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "socialObj (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Graphs\n",
    "\n",
    "function create_graph(start_node, en_node)\n",
    "    @assert Base.length(start_node)==Base.length(en_node)\n",
    "\n",
    "    no_node = max(maximum(start_node), maximum(en_node))\n",
    "    no_arc = Base.length(start_node)\n",
    "\n",
    "    graph = simple_inclist(no_node)\n",
    "    for i=1:no_arc \n",
    "        add_edge!(graph, start_node[i], en_node[i])\n",
    "    end\n",
    "    return graph\n",
    "end\n",
    "\n",
    "function get_vector(state, origin, destination, link_dic)\n",
    "    current = destination\n",
    "    parent = -1\n",
    "    x = zeros(Int, maximum(link_dic))\n",
    "\n",
    "    while parent != origin\n",
    "        parent = state.parents[current]\n",
    "        link_idx = link_dic[parent,current]\n",
    "        if link_idx != 0\n",
    "            x[link_idx] = 1\n",
    "        end\n",
    "        current = parent\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "function BPR(flowVec, fcoeffs, free_flow_time, capacity)\n",
    "    bpr = similar(flowVec)\n",
    "    for a = 1:length(bpr)\n",
    "        bpr[a] = free_flow_time[a] * sum([fcoeffs[i] * (flowVec[a]/capacity[a])^(i-1) for i = 1:length(fcoeffs)])\n",
    "    end\n",
    "    return bpr\n",
    "end\n",
    "\n",
    "function all_or_nothing(graph, link_dic, travel_time, demands, start_node, numZones)\n",
    "    state = []\n",
    "    path = []\n",
    "    x = zeros(size(start_node))\n",
    "\n",
    "    for r=1:numZones\n",
    "        # for each origin node r, find shortest paths to all destination nodes\n",
    "        state = dijkstra_shortest_paths(graph, travel_time, r)\n",
    "\n",
    "        for s=1:numZones\n",
    "            # for each destination node s, find the shortest-path vector\n",
    "            # load travel demand\n",
    "            x = x + demands[(r,s)] * get_vector(state, r, s, link_dic)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return x\n",
    "end\n",
    "\n",
    "\n",
    "function iniDemand(trip_file, numZones, flag=0)\n",
    "    file = open(trip_file)\n",
    "    demands = Dict{}()\n",
    "    for s=1:numZones\n",
    "        for t=1:numZones\n",
    "            demands[(s,t)] = 0\n",
    "        end\n",
    "    end    \n",
    "    s = 0\n",
    "    for line in eachline(file)\n",
    "        if contains(line, \"Origin\")\n",
    "            s = Int(parse(Float64,(split(line)[2])))\n",
    "        elseif contains(line, \";\")\n",
    "            pairs = split(line, \";\")\n",
    "            for pair in pairs[1:end-1]\n",
    "                if !contains(pair, \"\\n\")\n",
    "                    pair_vals = split(pair, \":\")\n",
    "                    t, demand = Int(parse(Float64,pair_vals[1])), parse(Float64,pair_vals[2])\n",
    "                    demands[(s,t)] = demand \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end                        \n",
    "    close(file)\n",
    "    return demands\n",
    "end\n",
    "\n",
    "\n",
    "function tapMSA(graph, link_dic, demands, fcoeffs, free_flow_time, capacity, start_node, en_node, numZones, numIter=500, tol=1e-6)\n",
    "    # Finding a starting feasible solution\n",
    "    travel_time = BPR(zeros(numLinks), fcoeffs, free_flow_time, capacity)\n",
    "    xl = all_or_nothing(graph, link_dic, travel_time, demands, start_node, numZones)\n",
    "\n",
    "    l = 1\n",
    "\n",
    "    while l < numIter\n",
    "        l += 1\n",
    "\n",
    "        xl_old = xl\n",
    "\n",
    "        # Finding yl\n",
    "        travel_time = BPR(xl, fcoeffs, free_flow_time, capacity )\n",
    "\n",
    "        yl = all_or_nothing(graph, link_dic, travel_time, demands, start_node, numZones)\n",
    "\n",
    "        # assert(yl != xl)\n",
    "\n",
    "        xl = xl + (yl - xl)/l\n",
    "\n",
    "        xl_new = xl\n",
    "\n",
    "        relative_gap = norm(xl_new - xl_old, 1) / norm(xl_new, 1)\n",
    "\n",
    "        if relative_gap < tol\n",
    "            break\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    tapFlows = Dict()\n",
    "\n",
    "    for i = 1:length(start_node)\n",
    "        key = (start_node[i], en_node[i])\n",
    "        tapFlows[key] = xl[i]\n",
    "    end\n",
    "\n",
    "    tapFlowVect = xl\n",
    "\n",
    "    return tapFlows, tapFlowVect\n",
    "end\n",
    "\n",
    "function extract_demandDict(out_dir, files_ID, month_w ,day, instance1, numZones)\n",
    "\tdemandsDict = Dict()\n",
    "\t# get ground trueth demands, indexed by 0\n",
    "\tdemandsDict[0] = iniDemand(out_dir * \"data_traffic_assignment_uni-class/\" * files_ID * \"_trips_\" * month_w * \"_\" * string(day) * \"_\" * instance1 * \".txt\", numZones)\n",
    "\t# get initial demands, indexed by 1\n",
    "\tdemandsDict[1] = iniDemand(out_dir * \"data_traffic_assignment_uni-class/\" * files_ID * \"_trips_\" * month_w * \"_\" * string(day) * \"_\" * instance1 * \".txt\", numZones, 1)\n",
    "\n",
    "\treturn demandsDict\n",
    "end\n",
    "\n",
    "function demandsDicToVec(demandsDic, odPairLabel_)\n",
    "    demandsVec = zeros(length(odPairLabel_))\n",
    "    for i = 1:length(demandsVec)\n",
    "        demandsVec[i] = demandsDic[(odPairLabel_[\"$i\"][1], odPairLabel_[\"$i\"][2])]\n",
    "    end\n",
    "    return demandsVec\n",
    "end\n",
    "\n",
    "function demandsVecToDic(demandsVec, odPairLabel_)\n",
    "    demandsDic = Dict{}()\n",
    "    for i = 1:numNodes\n",
    "        demandsDic[(i, i)] = 0\n",
    "    end\n",
    "    for i = 1:length(demandsVec)\n",
    "        demandsDic[(odPairLabel_[\"$i\"][1], odPairLabel_[\"$i\"][2])] = demandsVec[i]\n",
    "    end\n",
    "    return demandsDic\n",
    "end\n",
    "\n",
    "function arcData(arc_file)\n",
    "    arcs = Dict()\n",
    "    file = open(arc_file)\n",
    "    inHeader=true\n",
    "    for line in eachline(file)\n",
    "        if inHeader\n",
    "            inHeader = !contains(line, \"Init node\")\n",
    "            continue\n",
    "        end\n",
    "        vals = split(line, )\n",
    "        arcs[(parse(Int, vals[1]), parse(Int, vals[2]))] = Arc(parse(Int, vals[1]), parse(Int, vals[2]), parse(Float64, vals[3]), parse(Float64, vals[5]))\n",
    "    end\n",
    "    close(file) \n",
    "    return arcs\n",
    "end\n",
    "\n",
    "\n",
    "# add flow data to arcs\n",
    "function observFlow(arc_file, tapFlowDic)\n",
    "    arcs = arcData(arc_file)\n",
    "    ix = 0 \n",
    "    for key in keys(arcs)\n",
    "        arcs[key].flow = tapFlowDic[key]\n",
    "    end\n",
    "    return arcs\n",
    "end\n",
    "\n",
    "\n",
    "function objF(graph, link_dic, gamma1, gamma2, demandsVec, demandsVec0, tapFlowVecDict, fcoeffs, free_flow_time, capacity, start_node, en_node, numZones, odPairLabel_)\n",
    "    demandsDic = demandsVecToDic(demandsVec, odPairLabel_)\n",
    "    tapFlowVec = tapMSA(graph, link_dic, demandsDic, fcoeffs, free_flow_time, capacity, start_node, en_node, numZones)[2]\n",
    "    return gamma1 * sum([(demandsVec[i] - demandsVec0[i])^2 for i = 1:length(demandsVec)]) + gamma2 * sum([(tapFlowVec[a] - tapFlowVecDict[a])^2 for a = 1:length(tapFlowVec)])\n",
    "end     \n",
    "\n",
    "function tapFlowVecToLinkCostDict(tapFlowVec, fcoeffsInvVI, free_flow_time, capacity)\n",
    "    linkCostVec = BPR(tapFlowVec, fcoeffsInvVI, free_flow_time, capacity)\n",
    "    temp_dict = Dict{}()\n",
    "    for i in 1:length(linkCostVec)\n",
    "        temp_dict[\"$(i-1)\"] = linkCostVec[i]\n",
    "    end\n",
    "    return temp_dict\n",
    "end\n",
    "\n",
    "# compute the gradient\n",
    "function gradient_(gamma1, gamma2, demandsVec, demandsVec0, tapFlowVec, observFlowVec, jacob, numODpairs, numLinks)\n",
    "    gradi = zeros(numODpairs)\n",
    "    for i = 1:numODpairs\n",
    "        gradi[i] = 2 * gamma1 * (demandsVec[i] - demandsVec0[i]) + 2 * gamma2 * sum([(tapFlowVec[j] - observFlowVec[j]) * jacob[i, j] for j = 1:numLinks])\n",
    "    end\n",
    "    return gradi\n",
    "end\n",
    "    \n",
    "function descDirec(gamma1, gamma2, demandsVec, demandsVec0, tapFlowVec, observFlowVec, jacob, numODpairs, numLinks)\n",
    "    gradi = gradient_(gamma1, gamma2, demandsVec, demandsVec0, tapFlowVec, observFlowVec, jacob, numODpairs, numLinks)\n",
    "    h = similar(gradi)\n",
    "    for i = 1:length(gradi)\n",
    "        h[i] = -1 * gradi[i]\n",
    "    end\n",
    "    return h\n",
    "end\n",
    "\n",
    "\n",
    "# compute a search direction\n",
    "function searchDirec(demandsVec, descDirect, epsilon_1)\n",
    "    h = descDirect\n",
    "    h_ = similar(h)\n",
    "    for i = 1:length(h)\n",
    "            if (demandsVec[i] > epsilon_1) || (demandsVec[i] <= epsilon_1 && h[i] > 0)\n",
    "            h_[i] = h[i]\n",
    "        else\n",
    "            h_[i] = 0\n",
    "        end\n",
    "    end\n",
    "    return h_\n",
    "end\n",
    "\n",
    "# line search\n",
    "function thetaMax(demandsVec, searchDirect)\n",
    "    h_ = searchDirect\n",
    "    thetaList = Float64[]\n",
    "    for i = 1:length(h_)\n",
    "        if h_[i] < 0\n",
    "            push!(thetaList, - demandsVec[i]/h_[i])\n",
    "        end\n",
    "    end\n",
    "    theta_max = minimum(thetaList)\n",
    "    return theta_max\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function armijo(gamma1, gamma2, objFunOld, demandsVecOld, demandsVec0, tapFlowVecDict, fcoeffs, searchDirec, thetaMax, Theta, N, graph, link_dic, free_flow_time, capacity, start_node, en_node, numZones , odPairLabel_)\n",
    "    demandsVecList = Array{Float64}[]\n",
    "    objFunList = Float64[]\n",
    "    push!(demandsVecList, demandsVecOld)\n",
    "    push!(objFunList, objFunOld)\n",
    "    for n = 0:N\n",
    "        demandsVecNew = similar(demandsVecOld)\n",
    "        for i = 1:length(demandsVecOld)\n",
    "            demandsVecNew[i] = demandsVecOld[i] + (thetaMax/(Theta^n)) * searchDirec[i] \n",
    "        end\n",
    "        \n",
    "        objFun_New = objF(graph, link_dic, gamma1, gamma2, demandsVecNew, demandsVec0, tapFlowVecDict, fcoeffs, free_flow_time, capacity, start_node, en_node, numZones , odPairLabel_)\n",
    "    \tpush!(demandsVecList, demandsVecNew)\n",
    "    \tpush!(objFunList, objFun_New)\n",
    "    end\n",
    "    idx = indmin(objFunList)\n",
    "    objFunNew = objFunList[idx]\n",
    "    assert(objFunNew <= objFunOld)\n",
    "    return demandsVecList[idx], objFunNew\n",
    "end\n",
    "\n",
    "function BPRSocial(flowVec, fcoeffs, free_flow_time, capacity)\n",
    "    bpr = similar(flowVec)\n",
    "    # refer to [Page 50; Patriksson 1994, 2015]\n",
    "    for a = 1:length(bpr)\n",
    "        bpr[a] = free_flow_time[a] * sum([fcoeffs[i] * (flowVec[a]/capacity[a])^(i-1) for i = 1:length(fcoeffs)])\n",
    "        + free_flow_time[a] * sum([fcoeffs[i] * (i-1) * (flowVec[a]/capacity[a])^(i-1) for i = 2:length(fcoeffs)])\n",
    "    end\n",
    "    return bpr\n",
    "end\n",
    "\n",
    "\n",
    "function tapMSASocial(demands, fcoeffs, graph, link_dic, start_node, en_node, free_flow_time, capacity, numLinks, numZones, numIter=1000, tol=1e-6)\n",
    "    # Finding a starting feasible solution\n",
    "    travel_time = BPRSocial(zeros(numLinks), fcoeffs, free_flow_time, capacity)\n",
    "    xl = all_or_nothing(graph, link_dic, travel_time, demands, start_node, numZones)\n",
    "\n",
    "    l = 1\n",
    "\n",
    "    while l < numIter\n",
    "        l += 1\n",
    "        xl_old = xl\n",
    "\n",
    "        # Finding yl\n",
    "        travel_time = BPRSocial(xl, fcoeffs, free_flow_time, capacity)\n",
    "        yl = all_or_nothing(graph, link_dic, travel_time, demands, start_node, numZones)\n",
    "        \n",
    "        # assert(yl != xl)\n",
    "        xl = xl + (yl - xl)/l\n",
    "        xl_new = xl\n",
    "\n",
    "        relative_gap = norm(xl_new - xl_old, 1) / norm(xl_new, 1)\n",
    "        if relative_gap < tol\n",
    "            break\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "\n",
    "    tapFlows = Dict()\n",
    "\n",
    "    for i = 1:length(start_node)\n",
    "        key = (start_node[i], en_node[i])\n",
    "        tapFlows[key] = xl[i]\n",
    "    end\n",
    "\n",
    "    tapFlowVect = xl\n",
    "\n",
    "    return tapFlows, tapFlowVect\n",
    "end\n",
    "\n",
    "\n",
    "function socialObj(linkFlowVec, free_flow_time, polyDeg, fcoeffs, capacity, numLinks)\n",
    "    objVal = sum([sum([free_flow_time[a] * fcoeffs[i] * linkFlowVec[a]^i / capacity[a]^(i-1) for i=1:polyDeg]) \n",
    "        for a = 1:numLinks])\n",
    "    return objVal\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adjustingODdemands (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objFunDict = Dict()\n",
    "\n",
    "\n",
    "\n",
    "function adjustingODdemands(instance, day, cnt, out_dir, month_w, files_ID, ta_data, link_list,numNodes, gamma1, gamma2 )\n",
    "    ## Load initialization \n",
    "    flow_observ, link_vector = GLS_julia.GLS_juliaf(instance);\n",
    "\n",
    "    # demands from GLS\n",
    "    g_0 = read_demand_file(out_dir * \"OD_demands/OD_demand_matrix_\" * month_w * \"_\" * \"full\" * \"_weekday_\" * instance * files_ID * \".txt\", numNodes)\n",
    "\n",
    "\n",
    "    # cost function parameters\n",
    "    coeffs_dict_Apr_PM_ = readstring(out_dir * \"coeffs_dict_\" * month_w *  \"_\" * instance * \".json\");\n",
    "    coeffs_dict_Apr_PM_ = JSON.parse(coeffs_dict_Apr_PM_);\n",
    "\n",
    "    # cross-validation best key selection\n",
    "    best_key = readstring(out_dir * \"cross_validation_best_key/cross_validation_best_key_\" * month_w * \"_\" * \"full\" * \"_\" * instance * \".json\");\n",
    "    best_key = JSON.parse(best_key);\n",
    "    #best_key = \"(7, 0.5, 1000.0, 1)\"\n",
    "    fcoeffs = coeffs_dict_Apr_PM_[best_key];\n",
    "    polyDeg = length(fcoeffs);\n",
    "\n",
    "    # load network\n",
    "    ta_data = load_ta_network_(out_dir, files_ID, month_w, day,  instance);\n",
    "\n",
    "    # Load OdPairLabel\n",
    "    odPairLabel_ = readstring(out_dir * \"od_pair_label_dict__refined.json\");\n",
    "    odPairLabel_ = JSON.parse(odPairLabel_);\n",
    "\n",
    "    # Renaming variables\n",
    "    numNodes = maximum(map(pair->pair[1], keys(g_0)));\n",
    "    start_node = ta_data.start_node;\n",
    "    end_node = ta_data.end_node;\n",
    "    capacity = ta_data.capacity;\n",
    "    free_flow_time = ta_data.free_flow_time;\n",
    "    number_of_zones = ta_data.number_of_zones;\n",
    "    numLinks = size(start_node)[1];\n",
    "\n",
    "    numODpairs = numNodes * (numNodes - 1);\n",
    "    graph = create_graph(start_node, end_node);\n",
    "    link_list = sparse(start_node, end_node, 1:numLinks);\n",
    "\n",
    "    # Run MSA and adjust demand vector\n",
    "    tapFlows = Dict();\n",
    "    tapFlowVect = Dict();\n",
    "    tapFlowDicDict = Dict();\n",
    "    tapFlowVecDict = Dict();\n",
    "    linkCostDicDict = Dict();\n",
    "    jacobiSpiessDict = Dict();\n",
    "    jacobDict = Dict();\n",
    "    descDirecDict = Dict();\n",
    "    searchDirecDict = Dict();\n",
    "    thetaMaxDict = Dict();\n",
    "    demandsVecDict = Dict();\n",
    "    demandsDiffDict = Dict();\n",
    "    norObjFunDict = Dict();\n",
    "    tapSocialFlowDicDict = Dict();\n",
    "    tapSocialFlowVecDict = Dict();\n",
    "    user_sol_dict = Dict();\n",
    "    social_sol_dict = Dict();\n",
    "    PoA_dict = Dict();\n",
    "    \n",
    "    #demandsVecDict[0] = demandsDicToVec(g_0, odPairLabel_);\n",
    "    #demandsDiffDict[1] = norm(demandsDicToVec(demandsDict[1], odPairLabel_) - demandsDicToVec(g_0, odPairLabel_))/\n",
    "    #                     norm(demandsDicToVec(g_0, odPairLabel_));\n",
    "\n",
    "    if isdir(out_dir * \"demandsDict\") == false\n",
    "            mkdir(out_dir * \"demandsDict\");\n",
    "    end\n",
    "\n",
    "    #obj_dict[day] = demandsDictFixed(demandsDict, flow_observ,link_vector, graph, ta_data, link_dic, day, gamma1, gamma2, \n",
    "    #    out_dir, files_ID, month_w, instance, key_, free_flow_time, capacity, start_node, en_node, numZones, cnt)\n",
    "\n",
    "\n",
    "    xl = flow_observ[:, cnt]\n",
    "    tapFlows[0] = Dict()\n",
    "    for i = 1:length(start_node)\n",
    "        key = link_vector[i]\n",
    "        tapFlows[0][key] = xl[i]\n",
    "    end\n",
    "\n",
    "    tapFlowVecDict[0] = [];\n",
    "    for i = 1:length(start_node)\n",
    "        key = link_vector[i];\n",
    "        append!(tapFlowVecDict[0], tapFlows[0][key])\n",
    "    end\n",
    "\n",
    "    network_data_file = files_ID * \"_net_\" * month_w * \"_full_\" * instance * \".txt\";\n",
    "    arcsDict = observFlow(out_dir  * \"data_traffic_assignment_uni-class/\" * network_data_file, tapFlows[0]);\n",
    "\n",
    "    demandsVecDict[0] = demandsDicToVec(g_0, odPairLabel_);\n",
    "    demandsVecDict[1] = demandsDicToVec(g_0, odPairLabel_);\n",
    "\n",
    "    objFunDict[1] = objF(graph, link_list, gamma1, gamma2, demandsVecDict[0], \n",
    "        demandsVecDict[0], tapFlowVecDict[0], fcoeffs, free_flow_time, capacity, start_node, end_node, numZones, odPairLabel_);\n",
    "\n",
    "    demandsDic = demandsVecToDic(demandsVecDict[0], odPairLabel_)\n",
    "\n",
    "    # get initial flow vector (corresponding to initial demands)\n",
    "    tapFlows[1], tapFlowVecDict[1] = tapMSA(graph, link_list, g_0, fcoeffs, free_flow_time, capacity, start_node, end_node, number_of_zones);\n",
    "\n",
    "    # Computation of a Descent direction \n",
    "    linkCostDicDict[1] = tapFlowVecToLinkCostDict(tapFlowVecDict[1], fcoeffs, free_flow_time, capacity);\n",
    "    #linkCostDicDict[1][\"0\"], link_length_list[1]\n",
    "    jacobiSpiessDict[1] = Compute_Jacobian.jacobianSpiess(numNodes, numLinks, numODpairs, od_pairs, link_list_js, [linkCostDicDict[1][\"$(i)\"] for i=0:numLinks-1]);\n",
    "\n",
    "    demandsDict = extract_demandDict(out_dir, files_ID, month_w ,day, instance, numZones);\n",
    "\n",
    "    # maximum number of iterations\n",
    "    N = 100;\n",
    "\n",
    "    # Armijo rule parameters\n",
    "    rho = 2;\n",
    "    M = 10;\n",
    "\n",
    "    # search direction parameter\n",
    "    epsilon_1 = 0;\n",
    "\n",
    "    # stop criterion parameter\n",
    "    epsilon_2 = 1e-20;\n",
    "    obj = 9999999999999\n",
    "\n",
    "    las = 0\n",
    "\n",
    "    for l = 1:N\n",
    "        jacobDict[l] = jacobiSpiessDict[l]\n",
    "\n",
    "        descDirecDict[l] = descDirec(gamma1, gamma2, demandsVecDict[l], demandsVecDict[0],  tapFlowVecDict[l],\n",
    "                tapFlowVecDict[0], jacobDict[l], numODpairs, numLinks);\n",
    "\n",
    "        demandsVecDict[l] = demandsDicToVec(demandsDict[l], odPairLabel_);\n",
    "\n",
    "        searchDirecDict[l] = searchDirec(demandsVecDict[l], descDirecDict[l], epsilon_1);\n",
    "\n",
    "        thetaMaxDict[l] = thetaMax(demandsVecDict[l], searchDirecDict[l]);\n",
    "\n",
    "        demandsVecDict[l+1] = similar(demandsVecDict[0]);\n",
    "\n",
    "        demandsVecDict[l+1], objFunDict[l+1] = armijo(gamma1, gamma2, objFunDict[l], demandsVecDict[l], demandsVecDict[0], tapFlowVecDict[0], fcoeffs, \n",
    "                searchDirecDict[l], thetaMaxDict[l], rho, M, graph, link_list, free_flow_time, capacity, start_node, end_node, numZones, odPairLabel_);\n",
    "\n",
    "        demandsDict[l+1] = demandsVecToDic(demandsVecDict[l+1], odPairLabel_);\n",
    "\n",
    "        tapFlows[l+1], tapFlowVecDict[l+1] = tapMSA(graph, link_list, demandsDict[l+1], fcoeffs, free_flow_time, capacity, start_node, end_node, numZones);\n",
    "\n",
    "        arcsDict[l+1] = observFlow(out_dir  * \"data_traffic_assignment_uni-class/\" * network_data_file, tapFlows[l+1]);\n",
    "\n",
    "        linkCostDicDict[l+1] = tapFlowVecToLinkCostDict(tapFlowVecDict[l+1], fcoeffs, free_flow_time, capacity);\n",
    "\n",
    "        jacobiSpiessDict[l+1] = Compute_Jacobian.jacobianSpiess(numNodes, numLinks, numODpairs, od_pairs,\n",
    "                                                      link_list_js, [linkCostDicDict[l+1][\"$(i)\"] for i=0:numLinks-1]);\n",
    "\n",
    "        demandsDiffDict[l+1] = norm(demandsVecDict[l+1] - demandsVecDict[0]) / norm(demandsVecDict[0]);\n",
    "\n",
    "        obj =  objFunDict[1] - objFunDict[l]\n",
    "\n",
    "        las = l\n",
    "            # stopping criterion\n",
    "        if (objFunDict[l] - objFunDict[l+1]) / objFunDict[1] < epsilon_2\n",
    "            break\n",
    "        end\n",
    "\n",
    "\n",
    "        println(\"iteration $(l) finished...\")\n",
    "\n",
    "    end\n",
    "\n",
    "    # normalize objective function value\n",
    "    for a = 1:(length(objFunDict))\n",
    "        norObjFunDict[a] = objFunDict[a] / objFunDict[1];\n",
    "    end\n",
    "\n",
    "    # write files\n",
    "    outfile = open(out_dir * \"demandsDict/demandsVecDict$(day)_\" * month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, demandsVecDict)\n",
    "    close(outfile)\n",
    "\n",
    "    outfile = open(out_dir * \"demandsDict/demandsDict$(day)_\" * month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, demandsDict)\n",
    "    close(outfile)\n",
    "\n",
    "    outfile = open(out_dir * \"demandsDict/tapFlowDicDict$(day)_\" * month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, tapFlows)\n",
    "    close(outfile)\n",
    "\n",
    "    outfile = open(out_dir * \"demandsDict/tapFlowVecDict$(day)_\" * month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, tapFlowVecDict)\n",
    "    close(outfile)\n",
    "\n",
    "    outfile = open(out_dir * \"demandsDict/jacobi$(day)_\" * month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, jacobiSpiessDict[las])\n",
    "    close(outfile)\n",
    "\n",
    "    demandsDict[length(demandsDict)-1]\n",
    "    demandsDict_ = Dict{}()\n",
    "\n",
    "    for key in keys(demandsDict[length(demandsDict)-1])\n",
    "        demandsDict_[key] = demandsDict[length(demandsDict)-1][key]\n",
    "    end\n",
    "\n",
    "    outfile = open(out_dir * \"demandsDict/demandsDictFixed$(day)_\"* month_w * \"_\" * instance * \".json\", \"w\")\n",
    "    JSON.print(outfile, demandsDict_)\n",
    "    close(outfile)\n",
    "\n",
    "    # Calculating POA\n",
    "    tapSocialFlowDicDict[day], tapSocialFlowVecDict[day] =  tapMSASocial(demandsDict_, fcoeffs, graph, link_list, start_node, end_node, free_flow_time, capacity, numLinks, numZones);\n",
    "    #tapSocialFlowDicDict[day] = socialOpt(out_dir, files_ID, instance, demandsVecDict[las], polyDeg, free_flow_time, fcoeffs, capacity)\n",
    "    \n",
    "    \n",
    "    #user_sol_dict[day] = socialObj(flow_observ[:, cnt], free_flow_time, polyDeg, fcoeffs, capacity, numLinks) ;\n",
    "    user_sol_dict[day] = socialObj(tapFlowVecDict[las], free_flow_time, polyDeg, fcoeffs, capacity, numLinks) ;\n",
    "    social_sol_dict[day] = socialObj(tapSocialFlowVecDict[day], free_flow_time, polyDeg, fcoeffs, capacity, numLinks);\n",
    "    \n",
    "    PoA_dict[day] = user_sol_dict[day] / social_sol_dict[day];\n",
    "    \n",
    "    println(\"-----------------------------------------\")\n",
    "    println(\"day $(day) finished...\")\n",
    "    println(\"PoA for day $(day) and instance \" * instance * \" is \" * string(PoA_dict[day]))\n",
    "    println(\"-----------------------------------------\")\n",
    "    \n",
    "    return PoA_dict[day]\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 finished...\n",
      "iteration 2 finished...\n",
      "iteration 3 finished...\n",
      "iteration 4 finished...\n",
      "iteration 5 finished...\n",
      "iteration 6 finished...\n",
      "iteration 7 finished...\n",
      "iteration 8 finished...\n",
      "iteration 9 finished...\n",
      "iteration 10 finished...\n",
      "iteration 11 finished...\n",
      "iteration 12 finished...\n",
      "iteration 13 finished...\n",
      "iteration 14 finished...\n",
      "iteration 15 finished...\n",
      "iteration 16 finished...\n",
      "iteration 17 finished...\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: socialOpt not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: socialOpt not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1madjustingODdemands\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Int64, ::Int64, ::String, ::String, ::String, ::TA_Data, ::SparseMatrixCSC{Int64,Int64}, ::Int64, ::Int64, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\In[9]:208\u001b[22m\u001b[22m",
      " [2] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[10]:14\u001b[22m\u001b[22m [inlined]",
      " [3] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18 finished...\n"
     ]
    }
   ],
   "source": [
    "PoA_dict = Dict()\n",
    "day = 3\n",
    "cnt = 2\n",
    "instance = \"PM\"\n",
    "gamma1 = 0\n",
    "gamma2 = 1\n",
    "ta_data = load_ta_network_(out_dir, files_ID, month_w, day,  instance);\n",
    "link_list = sparse(ta_data.start_node, ta_data.end_node, 1:numLinks);\n",
    "\n",
    "cnt = 0\n",
    "#for instance in instances_1\n",
    "    for day in week_day_Apr_list\n",
    "        cnt += 1\n",
    "        PoA_dict[day] = adjustingODdemands(instance, day, cnt, out_dir, month_w, files_ID, ta_data, link_list, numNodes, gamma1, gamma2 )\n",
    "    end\n",
    "#end\n",
    "println(PoA_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 0 entries"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18 finished...\n"
     ]
    }
   ],
   "source": [
    "PoA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "socialOpt (generic function with 3 methods)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Ipopt\n",
    "function socialOpt(out_dir, files_ID, instance1, demandsVec, polyDeg, free_flow_time, fcoeffs, capacity)\n",
    "  \n",
    "    #load OD pair-route incidence\n",
    "    odPairRoute = readstring(out_dir * \"od_pair_route_incidence_\" * instance1 *  files_ID * \".json\");\n",
    "    odPairRoute = JSON.parse(odPairRoute);\n",
    "\n",
    "    for route in keys(odPairRoute)\n",
    "        if odPairRoute[route]>0\n",
    "            odPairRoute[route] = 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #load link labels\n",
    "    linkLabel = readstring(out_dir * \"link_label_dict.json\");\n",
    "    linkLabel = JSON.parse(linkLabel);\n",
    "    \n",
    "    #load link-route incidence\n",
    "    linkRoute = readstring(out_dir * \"link_route_incidence_\" * instance1 *  files_ID * \".json\");\n",
    "    linkRoute = JSON.parse(linkRoute);\n",
    "    \n",
    "    \n",
    "    m = Model(solver=IpoptSolver());\n",
    "\tnumLinks = length(linkLabel)\n",
    "\tnumRoute = length(linkRoute)\n",
    "\t#numRoute = 400\n",
    "\n",
    "\tnumOD = length(demandsVec)\n",
    "\n",
    "\t@variable(m, linkFlow[1:numLinks])\n",
    "\t@variable(m, pathFlow[1:numRoute])\n",
    "\n",
    "\tpathFlowSum = Dict()\n",
    "\n",
    "\tfor i=1:numOD\n",
    "\t    pathFlowSum[i] = 0\n",
    "\t    for j=1:numRoute\n",
    "\t        if \"$(i)-$(j)\" in keys(odPairRoute)\n",
    "\t            pathFlowSum[i] += pathFlow[j]\n",
    "\t        end\n",
    "\t    end\n",
    "\t    @constraint(m, pathFlowSum[i] == demandsVec[i])\n",
    "\tend\n",
    "\n",
    "\tpathFlowLinkSum = Dict()\n",
    "\n",
    "\n",
    "\n",
    "\tfor a=1:numLinks\n",
    "\t    pathFlowLinkSum[a] = 0\n",
    "\t    for j=1:numRoute\n",
    "\t        if \"$(a)-$(j)\" in keys(linkRoute)\n",
    "\t            pathFlowLinkSum[a] += pathFlow[j];\n",
    "\t        end\n",
    "\t    end\n",
    "\t    @constraint(m, pathFlowLinkSum[a] == linkFlow[a]);\n",
    "\tend\n",
    "\n",
    "\n",
    "\n",
    "\tfor j=1:numRoute\n",
    "\t    @constraint(m, pathFlow[j] >= 0);\n",
    "\tend\n",
    "\n",
    "\n",
    "\t#@expression(m, f, sum{free_flow_time[a]*linkFlow[a] + .03*free_flow_time[a]*((linkFlow[a])^5)/((capacity[a])^4), a = 1:numLinks} )\n",
    "\n",
    "\n",
    "\t@NLexpression(m, f, sum{ free_flow_time[a] * fcoeffs[i]  *linkFlow[a]^i / capacity[a]^(i-1) , i = 1:polyDeg , a = 1:numLinks }) ;\n",
    "#=\n",
    "\t@NLexpression(m, f, sum{free_flow_time[a] * fcoeffs[1] * linkFlow[a] +\n",
    "\t        free_flow_time[a] * fcoeffs[2] * linkFlow[a]^2 / capacity[a] +\n",
    "\t        free_flow_time[a] * fcoeffs[3] * linkFlow[a]^3 / capacity[a]^2 +\n",
    "\t        free_flow_time[a] * fcoeffs[4] * linkFlow[a]^4 / capacity[a]^3 +\n",
    "\t        free_flow_time[a] * fcoeffs[5] * linkFlow[a]^5 / capacity[a]^4 +\n",
    "\t        free_flow_time[a] * fcoeffs[6] * linkFlow[a]^6 / capacity[a]^5 +\n",
    "\t\t\tfree_flow_time[a] * fcoeffs[7] * linkFlow[a]^7 / capacity[a]^6 , a = 1:numLinks})\n",
    "=#\n",
    "\t@NLobjective(m, Min, f);\n",
    "\t#print(m) \n",
    "\n",
    "\tsolve(m);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #load OD pair-route incidence\n",
    "    odPairRoute = readstring(out_dir * \"od_pair_route_incidence_\" * instance *  files_ID * \".json\");\n",
    "    odPairRoute = JSON.parse(odPairRoute);\n",
    "\n",
    "    for route in keys(odPairRoute)\n",
    "        if odPairRoute[route]>0\n",
    "            odPairRoute[route] = 1\n",
    "        end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: demandsVecDict not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: demandsVecDict not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "socialOpt(out_dir, files_ID, \"MD\", demandsVecDict[las])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: demandsDict not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: demandsDict not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "demandsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
